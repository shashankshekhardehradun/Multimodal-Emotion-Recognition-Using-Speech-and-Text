# Multimodal-Emotion-Recognition-Using-Speech-and-Text
Final project of the ECE-GY 7123 (Deep Learning) course

A deep learning model that incorporates both speech and its transcript to predict emotions accurately, using BERT and CNN to classify text and spectrograms respectively.
The spectrogram is used to train an image classification model, while the word embedding model is used with a Long Short-Term Memory Network (LSTM). The output from the two models has then been combined to produce a joint output.
